---
title: "vig_2_models"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
vignette: >
  %\VignetteIndexEntry{vig_2_models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(bage)
```



# Introduction

Describes conceptual model - model seen by users.

Also decribes estimation model - mathematically equivalent reformulation of model seen by TMB.


Note: this is describing the models we want to get to, not the ones we currently implement.

# Specification visible to users

## Likelihood

### Poisson


Let $y_i$ be a count of events (eg births) in cell $i = 1, \cdots, n$ and $w_i$ the corresponding exposure measure (with the possibility that $w_i \equiv 1). Then our Poisson model
\begin{align}
  y_i & \sim \text{Poisson}(\gamma_i w_i) \\
  \gamma_i & \sim \text{Gamma}\left(\xi^{-1}, (\mu_i \xi)^{-1}\right)
\end{align}
where the Gamma distribution has a shape-rate parameterisation. Parameter $\xi$ governs dispersion:
\begin{equation}
  \text{var}(y_i \mid \mu_i, \xi, w_i) = \mu_i w_i (1 + \xi \mu_i w_i ).
\end{equation}
We allow $\xi$ to equal 0, in which case the model reduces to 
\begin{equation}
  y_i \sim \text{Poisson}(\mu_i w_i).
\end{equation}


### Binomial


\begin{align}
  y_i & \sim \text{Binomial}(w_i, \gamma_i) \\
  \gamma_i & \sim \text{Beta}\left((1-\xi)\xi^{-1}\mu_i, (1-\xi)\xi^{-1}(1 - \mu_i)\right)
\end{align}
Parameter $\xi$ in this case governs intra-class correlation, which is closely related to dispersion [@enwiki:1140557862].

We allow $\xi$ to equal 0, in which case the model reduces to 
\begin{equation}
  y_i \sim \text{Binom}(w_i, \mu_i).
\end{equation}


### Normal

\begin{equation}
  y_i \sim \text{N}(\mu_i, w_i^{-1}\xi^2).
\end{equation}

### Log-Normal

\begin{equation}
  y_i \sim \text{LogNorm}(\mu_i, w_i^{-1}\xi^2).
\end{equation}


## Model for means

Let $\beta^{(m)}$, $m=1,\cdots,M$, denote a main effect or interaction, and let $\beta^{(0)}$ denote an intercept. Let $J_m$ denote the number of elements of $\beta^{(m)}$. Let $U^{(m)}$ be an $n \times J_m$ matrix of 1s and 0s, the $i$th row of which picks out the element of $\beta^{m}$ to use with cell $i$.

Let $g$ denote the log function in the case of Poisson models, the logit function in the case of binomial models, and the identity function in the case of normal models.

Our model for means is then

\begin{equation}
  g(\mu) = \sum_{m=0}^{M} U^{(m)} \beta^{(m)}
\end{equation}


## Prior for intercept

\begin{equation}
  \beta^{(0)} \sim \text{N}(0, (10s)^2)
\end{equation}

The $s$ here is a scale term that occurs throughout our models. It defined equals 1 in Poisson, binomial, and log-normal models, and equals the standard deviation of $y_i$ in the normal model.

## Priors for main effects

### Overall structure

\begin{equation}
  \beta^{(m)} = V \alpha^{(m)} + v
\end{equation}
where $V$ is a known $K^{(m)} \times J^{(m)}$ matrix, $K^{(m)} \le J^{(m)}$, and $v$ is a known vector with $J^{(m)}$ elements. $V$ can be the identical matrix, and $v$ can be composed entirely of 0s.


### Options for $V$, $v$

#### Spline


### Human Mortality Database


### Human Fertility Database


### Fractional Polynomials


### Options for $\alpha^{(m)}$

#### Normal

\begin{align}
  \alpha_j^{(m)} & \sim \text{N}\left(0, \tau_m^2 \right) \\
  \tau_m & \sim \text{N}^+(s^2)
\end{align}


#### First-order random walk

\begin{align}
  \alpha_j^{(m)} & = \alpha_{j-1}^{(m)} + \epsilon_j^{(m)} \\
  \epsilon_j^{(m)} & \sim \text{N}(0, \tau_m^2) \\
  \tau_m & \sim \text{N}^+(s^2)
\end{align}
subject to $\sum_{j=1}^{J_m}{\alpha_j^{(m)}} = 0$.


#### Second-order random walk

\begin{align}
  (\alpha_j^{(m)} - \alpha_{j-1}^{(m)}) & = (\alpha_{j-1}^{(m)} - \alpha_{j-2}^{(m)}) + \epsilon_j^{(m)} \\
  \epsilon_j^{(m)} & \sim \text{N}(0, \tau_m^2) \\
  \tau_m & \sim \text{N}^+(s^2)
\end{align}
subject to $\sum_{j=1}^{J_m}{\alpha_j^{(m)}} = 0$.

#### AR1

\begin{align}
  \alpha_j^{(m)} & \sim \phi_m \alpha_{j-1}^{(m)} + \epsilon_j^{(m)} \\
  \epsilon_j^{(m)} & \sim \text{N}(0, \tau_m^2) \\
  \phi_m & = a_m + (b_m - a_m) \lambda_m \\
  \lambda_m & \sim \text{Beta}(2, 2) \\
  \tau_m & \sim \text{N}^+(s^2)
\end{align}

By default $a_m = 0.8$ and $b_m = 0.98$.

#### Linear

\begin{align}
  \alpha_j^{(m)} & \sim \lambda^{(m)} \tilde{j} + \epsilon_j^{(m)} \\
  \epsilon_j^{(m)} & \sim \text{N}(0, \tau_m^2) \\
  \lambda^{(m)} & \sim \text{N}(0, s^2) \\
  \tau_m & \sim \text{N}^+(s^2)
\end{align}
where $\tilde{j} = -\frac{J_m + 1}{J_m - 1} + \frac{2}{J_m - 1} j$.


#### LinearAR1

\begin{align}
  \alpha_j^{(m)} & \sim \lambda^{(m)} \tilde{j} + \epsilon_j^{(m)} \\
  \epsilon_j^{(m)} & \sim \phi_m \epsilon_{j-1}^{(m)} \\
  \phi_m & \sim \text{Beta}(2, 2) \\
  \tau_m & \sim \text{N}^+(s^2)
\end{align}
where $\tilde{j} = -\frac{J_m + 1}{J_m - 1} + \frac{2}{J_m - 1} j$.










### Spline


## Priors for dispersion terms

### Poisson

\begin{equation}
  p(\xi) = \frac{s}{2 \sqrt{\xi}}e^{-s \sqrt{\xi}}
\end{equation}
[@simpson2022priors] for some value of $s$. TODO - choice of $s$.

### Binomial

$\xi$ is bounded between 0 and 1, so exact form not crucial. 
\begin{equation}
  \xi \sim \text{Beta}(2, 2)
\end{equation}
boundary-avoiding prior (@gelman2014bayesian, p317).


### Normal

\begin{equation}
  \xi \sim \text{N+(0, s^2)}
\end{equation}
TODO - choice of $s$


### Log-Normal

\begin{equation}
  \xi \sim \text{N+(0, s^2)}
\end{equation}
TODO - choice of $s$

# Specification used internally

To facilitate estimation via TMB

- minimise dimension
- no explicit constraints on parameters
- all parameters continuous



## Likelihood

### Poisson

For $\xi > 0$, the user-visible model is equivalent to 
\begin{equation}
  y_i \sim \text{NegBinom}\left(\xi^{-1}, (1 + \mu_i w_i \xi)^{-1}\right),
\end{equation}
[@norton2018sampling; @simpson2022priors]. The $\gamma_i$ have, in effect, been integrated out, which makes the model much more efficient and scalable. When values for $\gamma_i$ are needed, we can generate them on the fly, using the fact that, for known values of $\mu_i, \xi_i$,
\begin{equation}
  \gamma_i \sim \text{Gamma}\left(y_i + \xi^{-1}, w_i + (\xi \mu_i)^{-1}\right).
\end{equation}



### Binomial

For $\xi > 0$, the user-visible model is equivalent to
\begin{equation}
  y_i \sim \text{BetaBinom}\left(w_i, (1-\xi)\xi^{-1}\mu_i, (1-\xi)\xi^{-1}(1 - \mu_i)\right).
\end{equation}
As with the Poisson model, we are able to integrate out the $\gamma_i$. Values for $\gamma_i$ can be generated using
\begin{equation}
  \gamma_i \sim \text{Beta}\left(y_i + (1-\xi)\xi^{-1}\mu_i, w_i - y_i + (1-\xi)\xi^{-1}(1-\mu_i)\right).
\end{equation}


### Normal

Same as user-visible model.

### Log-Normal

Same as user-visible model.


## Higher levels




# Appendix: Definitions


| Quantity | Definition                                          |
|:---------|:----------------------------------------------------|
| $n$      | Number of cells in classification.                   |
| $i$      | Index for cell, $i = 1, \cdots, n$.
| $y_i$    | Value of outcome variable.              |
| $w_i$    | Exposure, number of trials, or weight. |
| $\gamma_i$ | Super-population rate or probability. |
| $\mu_i$ | Cell means in prior model. |
| $\xi$   | Over-dispersion. |
| $s$ | Generic scale term used across model. Equal to 1 or $\text{sd}(y_k)$. |
| $\beta^{(0)}$ | Intercept |
| $\beta^{(m)}$ | Main effect or interaction. $m = 1, \cdots, M$.  |
| $\beta_j^{(m)}$ | $j$th element of $\beta^{(m)}$. $j = 1, \cdots, J_m$. |
| $\lambda^{(m)}$ | Parameter specific to main effect or interaction $m$. |





# References


